\documentclass[../main.tex]{subfiles} 
\usepackage{ctex}
\usepackage{xltxtra}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{mathdots}
\usepackage{amssymb}
\usepackage{cite}
\usepackage{appendix}
\usepackage{array}
\usepackage{subfigure}
\begin{document}

    首先可以感受到的是，该数据集相比起Kaggle传统的Titanic数据集难度可以说有了质的提升。Titanic数据集的缺失值数量相比起该数据集少了非常多，并且数据量和数据维度也有了提升。
    同时我觉得最大的难度在于，Titanic数据集我们可以根据现实场景进行适当的猜测，比如孩子和女性的存活率高于成年男性，身份地位较高的存活率高于身份地位较低，因此可以着重对于这几个特征进行探索。
    而该数据集除了题目中提供了信息，同一团队的人通常一起旅行，并没有提供任何的相关信息，因此需要通过自己的观察去发掘特征之间的相关性，进行缺失值的填充，这一步的数据预处理如果做得不好会非常影响后续模型的训练效果。

    在这次作业中训练的几种模型可以发现测试效果有着较大的差别，我认为更多是因为数据处理的问题，不同的模型数据处理形式以及特征编码应该是为不一样的，我的处理方式可能较适合树形模型的训练，因此决策树和以CART树为基学习器的CatBoost和Random Forest在测试中表现得效果较好。

    虽然说最好的模型在Kaggle上的测试的结果也只有80，但是在Kaggle的排行榜上第一名的得分为0.87，而第三名的得分已经降至0.81，所以我认为该题目的难度更多在于数据预处理如何去更好地填充缺失值和对于特征的进一步提取，比如说五个消费特征，我只能提取出是否有消费这个新特征，并对原始特征进行对数变换。
    这应该是不够的，该特征应该有更好的处理方式等待发掘。

    对比几种模型的训练效果，可以发现很多模型对于正类的错分概率较大，我认为是从重新调整的特征中并没有很好地学习到正类样本的分布方式。但是可以发现集成学习的效果相比起其他模型有着较为显著的提升，这可能与该数据集的复杂性有关。

    总的来说，这次课设是对于自己之前所学知识的一个应用，第一次经历了从数据预处理到模型选择，模型调参的一个完整过程，对于处理方法、模型参数、评估方法等有了更清晰的认识。

\end{document}